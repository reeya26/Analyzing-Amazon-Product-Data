{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1168693f",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "1. Importing the required libraries\n",
    "2. Creating S3 bucket -- Project_SageMaker\n",
    "3. Mapping train and test data in S3\n",
    "4. Mapping the path of the models in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7678bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker #if we are using any built-in algorithm\n",
    "import boto3\n",
    "from sagemaker.session import s3_input, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00f18ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-west-2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_region = boto3.session.Session().region_name\n",
    "print(my_region) # Just to make sure that the region is correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bdcb6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing buckets:\n",
      "  p-data-buckets\n"
     ]
    }
   ],
   "source": [
    "# Checking for the existing buckets\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "response = s3.list_buckets()\n",
    "\n",
    "# Output the bucket names\n",
    "print('Existing buckets:')\n",
    "for bucket in response['Buckets']:\n",
    "    print(f'  {bucket[\"Name\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7900200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name, region=None):\n",
    "    \"\"\"Create an S3 bucket in a specified region\n",
    "\n",
    "    If a region is not specified, the bucket is created in the S3 default\n",
    "    region (us-east-1).\n",
    "\n",
    "    :param bucket_name: Bucket to create\n",
    "    :param region: String region to create bucket in, e.g., 'us-west-2'\n",
    "    :return: True if bucket created, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # Create bucket\n",
    "    try:\n",
    "        if region is None:\n",
    "            s3_client = boto3.client('s3')\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            s3_client = boto3.client('s3', region_name=region)\n",
    "            location = {'LocationConstraint': region}\n",
    "            s3_client.create_bucket(Bucket=bucket_name,\n",
    "                                    CreateBucketConfiguration=location)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b02444bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "bucket= create_bucket('project-sagemaker-4', region = 'us-west-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "662bc425",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'project-sagemaker-3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b623c4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3:/project-sagemaker-3/sagemaker/output\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########## We manually created the paths for data and model folders #############\n",
    "##### Come back to this piece later ##########\n",
    "\n",
    "\n",
    "\n",
    "# Creating the paths where the trained models with versions will be stoored\n",
    "\n",
    "prefix = 'sagemaker' # model_name for our train model\n",
    "\n",
    "output_path = 's3://{}/{}/output'.format(bucket_name, prefix)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bec785c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_files/\n",
      "Data_files/amazon0302_copy.txt\n",
      "Models/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Listing out the content of the bucket\n",
    "\n",
    "conn = boto3.client('s3')\n",
    "contents = conn.list_objects(Bucket=bucket_name)['Contents']\n",
    "for f in contents:\n",
    "    print(f['Key'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
